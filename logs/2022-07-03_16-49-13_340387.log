2022-07-03 at 16:49:13 {'batch': 4, 'epochs': 3, 'save': 'dialogpt-finetune', 'lr': 5e-05, 'clip': 2.0, 'seed': 1234, 'context': 3, 'max_len': 128, 'prepare': False, 'grad_accumulate': 4, 'tensorboard': 'runs/', 'early_stop': 10}
2022-07-03 at 16:49:13 Working on GPU: cuda
2022-07-03 at 16:49:13 Loading Tokenizer ...
2022-07-03 at 16:49:24 Loading Saved Dataset ...
2022-07-03 at 16:49:55 Loading the model ...
2022-07-03 at 16:50:08 
Training the model ...

2022-07-03 at 16:50:08 Epoch: 0, Batch: 0, Loss: 5.586581707000732
2022-07-03 at 16:50:48 Epoch: 0, Batch: 100, Loss: 1.4551914118143827e-09
2022-07-03 at 16:51:28 Epoch: 0, Batch: 200, Loss: 0.0
