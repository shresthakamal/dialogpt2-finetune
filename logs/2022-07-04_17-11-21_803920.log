2022-07-04 at 17:11:21 {'batch': 8, 'epochs': 3, 'save': 'dialogpt-finetune', 'lr': 5e-05, 'clip': 2.0, 'seed': 1234, 'context': 3, 'max_len': 128, 'prepare': False, 'grad_accumulate': 8, 'tensorboard': 'runs/', 'early_stop': 10, 'eval': False}
2022-07-04 at 17:11:21 Working on GPU: cuda
2022-07-04 at 17:11:21 Loading Tokenizer ...
2022-07-04 at 17:11:32 Loading Saved Dataset ...
2022-07-04 at 17:12:01 Loading the model ...
2022-07-04 at 17:12:10 Model size: 354823168
2022-07-04 at 17:12:10 Training the model ...
2022-07-04 at 17:12:11 Epoch: 0, Batch: 0, Loss: 0.23250896453857423
2022-07-04 at 17:12:53 Epoch: 0, Batch: 100, Loss: 0.9718397518858733
2022-07-04 at 17:13:35 Epoch: 0, Batch: 200, Loss: 9.789246671232377e-07
2022-07-04 at 17:14:17 Epoch: 0, Batch: 300, Loss: 0.000207401229348676
2022-07-04 at 17:15:00 Epoch: 0, Batch: 400, Loss: 5.448632207105675e-07
2022-07-04 at 17:15:42 Epoch: 0, Batch: 500, Loss: 3.78501845119672e-07
2022-07-04 at 17:16:24 Epoch: 0, Batch: 600, Loss: 3.7948879707982994e-07
2022-07-04 at 17:17:06 Epoch: 0, Batch: 700, Loss: 5.182717944762771e-07
2022-07-04 at 17:17:48 Epoch: 0, Batch: 800, Loss: 4.159844479545427e-07
2022-07-04 at 17:18:30 Epoch: 0, Batch: 900, Loss: 2.616039197533837e-07
2022-07-04 at 17:19:12 Epoch: 0, Batch: 1000, Loss: 2.546128687441751e-07
2022-07-04 at 17:19:54 Epoch: 0, Batch: 1100, Loss: 2.6432480773053155e-07
2022-07-04 at 17:20:37 Epoch: 0, Batch: 1200, Loss: 2.4365758022781847e-07
2022-07-04 at 17:21:19 Epoch: 0, Batch: 1300, Loss: 2.181067873863185e-07
2022-07-04 at 17:22:01 Epoch: 0, Batch: 1400, Loss: 1.860461144076453e-07
2022-07-04 at 17:22:43 Epoch: 0, Batch: 1500, Loss: 1.7001577603537044e-07
2022-07-04 at 17:23:25 Epoch: 0, Batch: 1600, Loss: 1.559876624668277e-07
2022-07-04 at 17:24:07 Epoch: 0, Batch: 1700, Loss: 1.3776737812776218e-07
2022-07-04 at 17:24:49 Epoch: 0, Batch: 1800, Loss: 1.39249655006779e-07
2022-07-04 at 17:25:32 Epoch: 0, Batch: 1900, Loss: 1.3632820010656134e-07
2022-07-04 at 17:26:14 Epoch: 0, Batch: 2000, Loss: 1.1383623711225255e-07
2022-07-04 at 17:26:56 Epoch: 0, Batch: 2100, Loss: 1.2482123430856974e-07
2022-07-04 at 17:27:38 Epoch: 0, Batch: 2200, Loss: 1.0659504694032762e-07
2022-07-04 at 17:28:20 Epoch: 0, Batch: 2300, Loss: 9.982619548765115e-08
2022-07-04 at 17:29:02 Epoch: 0, Batch: 2400, Loss: 7.44860808410408e-08
2022-07-04 at 17:29:44 Epoch: 0, Batch: 2500, Loss: 6.9903187291942e-08
2022-07-04 at 17:30:26 Epoch: 0, Batch: 2600, Loss: 8.253811005332068e-08
