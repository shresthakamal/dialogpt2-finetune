2022-07-07 at 10:48:01 Preparing Dataset ...
2022-07-07 at 10:48:02 Creating TensorDataset and DataLoader ...
2022-07-07 at 10:49:19 Preparing Dataset ...
2022-07-07 at 10:49:19 Creating TensorDataset and DataLoader ...
2022-07-07 at 10:49:25 Training the model, num_training_steps: 28521
2022-07-07 at 10:49:28 --------------- Epoch: 0 ------------
2022-07-07 at 10:50:05 Epoch: 0, Batch: 100, Loss: 4.235229659080505
2022-07-07 at 10:50:42 Epoch: 0, Batch: 200, Loss: 3.633629631996155
2022-07-07 at 10:51:18 Epoch: 0, Batch: 300, Loss: 3.371673634052277
2022-07-07 at 10:51:55 Epoch: 0, Batch: 400, Loss: 3.2926591181755067
2022-07-07 at 10:52:31 Epoch: 0, Batch: 500, Loss: 3.2098080682754517
2022-07-07 at 10:54:16 Epoch: 0, Testing Loss: 3.0698313276114413
2022-07-07 at 10:54:53 Epoch: 0, Batch: 600, Loss: 3.1624114537239074
2022-07-07 at 10:55:29 Epoch: 0, Batch: 700, Loss: 3.179043254852295
2022-07-07 at 10:56:06 Epoch: 0, Batch: 800, Loss: 3.1188835096359253
2022-07-07 at 10:56:43 Epoch: 0, Batch: 900, Loss: 3.1619438982009886
2022-07-07 at 10:57:20 Epoch: 0, Batch: 1000, Loss: 3.0950654911994935
2022-07-07 at 10:59:02 Epoch: 0, Testing Loss: 2.9543804545419494
2022-07-07 at 10:59:38 Epoch: 0, Batch: 1100, Loss: 3.1103801250457765
2022-07-07 at 11:00:15 Epoch: 0, Batch: 1200, Loss: 3.0803449535369873
2022-07-07 at 11:00:52 Epoch: 0, Batch: 1300, Loss: 3.0198978424072265
2022-07-07 at 11:01:28 Epoch: 0, Batch: 1400, Loss: 3.029039297103882
2022-07-07 at 11:02:05 Epoch: 0, Batch: 1500, Loss: 3.0199926352500914
2022-07-07 at 11:03:50 Epoch: 0, Testing Loss: 2.904894470037232
2022-07-07 at 11:04:26 Epoch: 0, Batch: 1600, Loss: 3.0500971031188966
2022-07-07 at 11:05:03 Epoch: 0, Batch: 1700, Loss: 2.9751134967803954
2022-07-07 at 11:05:40 Epoch: 0, Batch: 1800, Loss: 2.986892033815384
2022-07-07 at 11:06:17 Epoch: 0, Batch: 1900, Loss: 2.9953839015960693
2022-07-07 at 11:06:53 Epoch: 0, Batch: 2000, Loss: 2.9405274391174316
2022-07-07 at 11:08:36 Epoch: 0, Testing Loss: 2.875232232705837
2022-07-07 at 11:09:12 Epoch: 0, Batch: 2100, Loss: 2.9325552368164063
2022-07-07 at 11:09:49 Epoch: 0, Batch: 2200, Loss: 2.916226406097412
2022-07-07 at 11:10:25 Epoch: 0, Batch: 2300, Loss: 2.9696342253685
2022-07-07 at 11:11:02 Epoch: 0, Batch: 2400, Loss: 2.9897437477111817
2022-07-07 at 11:11:39 Epoch: 0, Batch: 2500, Loss: 2.916375765800476
2022-07-07 at 11:13:24 Epoch: 0, Testing Loss: 2.8542694017414805
2022-07-07 at 11:14:00 Epoch: 0, Batch: 2600, Loss: 2.990049843788147
2022-07-07 at 11:14:37 Epoch: 0, Batch: 2700, Loss: 3.0045152497291565
2022-07-07 at 11:15:14 Epoch: 0, Batch: 2800, Loss: 2.893038569688797
2022-07-07 at 11:15:50 Epoch: 0, Batch: 2900, Loss: 2.97646372795105
2022-07-07 at 11:16:27 Epoch: 0, Batch: 3000, Loss: 2.9449646925926207
2022-07-07 at 11:18:10 Epoch: 0, Testing Loss: 2.834715026694826
2022-07-07 at 11:18:46 Epoch: 0, Batch: 3100, Loss: 2.8764998602867125
2022-07-07 at 11:19:23 Epoch: 0, Batch: 3200, Loss: 2.9274426245689393
2022-07-07 at 11:20:00 Epoch: 0, Batch: 3300, Loss: 2.926466615200043
2022-07-07 at 11:20:36 Epoch: 0, Batch: 3400, Loss: 2.895852837562561
2022-07-07 at 11:21:13 Epoch: 0, Batch: 3500, Loss: 2.9557242238521577
2022-07-07 at 11:22:58 Epoch: 0, Testing Loss: 2.8206724970649004
2022-07-07 at 11:23:35 Epoch: 0, Batch: 3600, Loss: 2.8582037329673766
2022-07-07 at 11:24:12 Epoch: 0, Batch: 3700, Loss: 2.88690580368042
2022-07-07 at 11:24:48 Epoch: 0, Batch: 3800, Loss: 2.919039001464844
2022-07-07 at 11:25:25 Epoch: 0, Batch: 3900, Loss: 2.909207384586334
2022-07-07 at 11:26:02 Epoch: 0, Batch: 4000, Loss: 2.8832240891456604
2022-07-07 at 11:27:44 Epoch: 0, Testing Loss: 2.8047532049645167
2022-07-07 at 11:28:21 Epoch: 0, Batch: 4100, Loss: 2.885538029670715
2022-07-07 at 11:28:57 Epoch: 0, Batch: 4200, Loss: 2.929247523546219
2022-07-07 at 11:29:34 Epoch: 0, Batch: 4300, Loss: 2.8436759996414183
2022-07-07 at 11:30:11 Epoch: 0, Batch: 4400, Loss: 2.8801142358779908
2022-07-07 at 11:30:47 Epoch: 0, Batch: 4500, Loss: 2.8832582902908324
2022-07-07 at 11:32:32 Epoch: 0, Testing Loss: 2.785942821033202
2022-07-07 at 11:33:09 Epoch: 0, Batch: 4600, Loss: 2.8755505192279815
2022-07-07 at 11:33:45 Epoch: 0, Batch: 4700, Loss: 2.8781943106651307
2022-07-07 at 11:34:22 Epoch: 0, Batch: 4800, Loss: 2.859030817747116
2022-07-07 at 11:34:59 Epoch: 0, Batch: 4900, Loss: 2.8463969111442564
2022-07-07 at 11:35:36 Epoch: 0, Batch: 5000, Loss: 2.8954060077667236
2022-07-07 at 11:37:18 Epoch: 0, Testing Loss: 2.778650067172158
2022-07-07 at 11:37:54 Epoch: 0, Batch: 5100, Loss: 2.902783136367798
2022-07-07 at 11:38:31 Epoch: 0, Batch: 5200, Loss: 2.927216784954071
2022-07-07 at 11:39:08 Epoch: 0, Batch: 5300, Loss: 2.878932659626007
2022-07-07 at 11:39:44 Epoch: 0, Batch: 5400, Loss: 2.8997413110733032
2022-07-07 at 11:40:21 Epoch: 0, Batch: 5500, Loss: 2.9149891889095305
2022-07-07 at 11:42:06 Epoch: 0, Testing Loss: 2.7721374717895673
2022-07-07 at 11:42:42 Epoch: 0, Batch: 5600, Loss: 2.8852694416046143
2022-07-07 at 11:43:19 Epoch: 0, Batch: 5700, Loss: 2.9383461117744445
2022-07-07 at 11:43:55 Epoch: 0, Batch: 5800, Loss: 2.8678423047065733
2022-07-07 at 11:44:32 Epoch: 0, Batch: 5900, Loss: 2.85682345867157
2022-07-07 at 11:45:09 Epoch: 0, Batch: 6000, Loss: 2.868409450054169
2022-07-07 at 11:46:54 Epoch: 0, Testing Loss: 2.763394378965294
2022-07-07 at 11:47:31 Epoch: 0, Batch: 6100, Loss: 2.7620439457893373
2022-07-07 at 11:48:08 Epoch: 0, Batch: 6200, Loss: 2.812695388793945
2022-07-07 at 11:48:44 Epoch: 0, Batch: 6300, Loss: 2.836537227630615
2022-07-07 at 11:49:21 Epoch: 0, Batch: 6400, Loss: 2.8865725564956666
2022-07-07 at 11:49:58 Epoch: 0, Batch: 6500, Loss: 2.8912708282470705
2022-07-07 at 11:51:40 Epoch: 0, Testing Loss: 2.757391590240587
2022-07-07 at 11:52:16 Epoch: 0, Batch: 6600, Loss: 2.8155571031570434
2022-07-07 at 11:52:53 Epoch: 0, Batch: 6700, Loss: 2.851496593952179
2022-07-07 at 11:53:30 Epoch: 0, Batch: 6800, Loss: 2.777003839015961
2022-07-07 at 11:54:06 Epoch: 0, Batch: 6900, Loss: 2.7846818470954897
2022-07-07 at 11:54:43 Epoch: 0, Batch: 7000, Loss: 2.882485681772232
2022-07-07 at 11:56:28 Epoch: 0, Testing Loss: 2.7545794134038197
2022-07-07 at 11:57:04 Epoch: 0, Batch: 7100, Loss: 2.833665428161621
2022-07-07 at 11:57:41 Epoch: 0, Batch: 7200, Loss: 2.8384357571601866
2022-07-07 at 11:58:18 Epoch: 0, Batch: 7300, Loss: 2.8449556732177737
2022-07-07 at 11:58:54 Epoch: 0, Batch: 7400, Loss: 2.836647274494171
2022-07-07 at 11:59:31 Epoch: 0, Batch: 7500, Loss: 2.8375671339035033
2022-07-07 at 12:01:16 Epoch: 0, Testing Loss: 2.74002217171738
2022-07-07 at 12:01:53 Epoch: 0, Batch: 7600, Loss: 2.813402473926544
2022-07-07 at 12:02:30 Epoch: 0, Batch: 7700, Loss: 2.85842857837677
2022-07-07 at 12:03:06 Epoch: 0, Batch: 7800, Loss: 2.8424012875556945
2022-07-07 at 12:03:43 Epoch: 0, Batch: 7900, Loss: 2.8215172052383424
2022-07-07 at 12:04:20 Epoch: 0, Batch: 8000, Loss: 2.864569835662842
2022-07-07 at 12:06:05 Epoch: 0, Testing Loss: 2.736908246331085
2022-07-07 at 12:06:41 Epoch: 0, Batch: 8100, Loss: 2.7679519128799437
2022-07-07 at 12:07:18 Epoch: 0, Batch: 8200, Loss: 2.7787840223312377
2022-07-07 at 12:07:54 Epoch: 0, Batch: 8300, Loss: 2.8850176453590395
2022-07-07 at 12:08:31 Epoch: 0, Batch: 8400, Loss: 2.832371003627777
2022-07-07 at 12:09:08 Epoch: 0, Batch: 8500, Loss: 2.8135417699813843
2022-07-07 at 12:10:53 Epoch: 0, Testing Loss: 2.7320139173369675
2022-07-07 at 12:11:30 Epoch: 0, Batch: 8600, Loss: 2.8238935899734496
2022-07-07 at 12:12:07 Epoch: 0, Batch: 8700, Loss: 2.7478407049179077
2022-07-07 at 12:12:43 Epoch: 0, Batch: 8800, Loss: 2.800953457355499
2022-07-07 at 12:13:20 Epoch: 0, Batch: 8900, Loss: 2.806952250003815
2022-07-07 at 12:13:57 Epoch: 0, Batch: 9000, Loss: 2.805546636581421
2022-07-07 at 12:15:39 Epoch: 0, Testing Loss: 2.7231923911636553
2022-07-07 at 12:16:16 Epoch: 0, Batch: 9100, Loss: 2.791895173788071
2022-07-07 at 12:16:52 Epoch: 0, Batch: 9200, Loss: 2.8248741912841795
2022-07-07 at 12:17:29 Epoch: 0, Batch: 9300, Loss: 2.7494769048690797
2022-07-07 at 12:18:06 Epoch: 0, Batch: 9400, Loss: 2.7404962944984437
2022-07-07 at 12:18:42 Epoch: 0, Batch: 9500, Loss: 2.7974230909347533
2022-07-07 at 12:20:28 Epoch: 0, Testing Loss: 2.718816292809139
2022-07-07 at 12:20:30 --------------- Epoch: 1 ------------
2022-07-07 at 12:21:07 Epoch: 1, Batch: 100, Loss: 2.809826090335846
2022-07-07 at 12:21:44 Epoch: 1, Batch: 200, Loss: 2.82477703332901
2022-07-07 at 12:22:21 Epoch: 1, Batch: 300, Loss: 2.778202373981476
2022-07-07 at 12:22:57 Epoch: 1, Batch: 400, Loss: 2.7898654210567475
2022-07-07 at 12:23:34 Epoch: 1, Batch: 500, Loss: 2.7850682139396667
2022-07-07 at 12:25:26 Epoch: 1, Testing Loss: 2.7192367596699816
2022-07-07 at 12:26:03 Epoch: 1, Batch: 600, Loss: 2.763815553188324
2022-07-07 at 12:26:39 Epoch: 1, Batch: 700, Loss: 2.7666761612892152
2022-07-07 at 12:27:16 Epoch: 1, Batch: 800, Loss: 2.7909637928009032
2022-07-07 at 12:27:53 Epoch: 1, Batch: 900, Loss: 2.7627178716659544
2022-07-07 at 12:28:30 Epoch: 1, Batch: 1000, Loss: 2.72105544090271
2022-07-07 at 12:30:15 Epoch: 1, Testing Loss: 2.709390958715871
2022-07-07 at 12:30:51 Epoch: 1, Batch: 1100, Loss: 2.782690360546112
2022-07-07 at 12:31:28 Epoch: 1, Batch: 1200, Loss: 2.7459993457794187
2022-07-07 at 12:32:04 Epoch: 1, Batch: 1300, Loss: 2.7101823222637176
2022-07-07 at 12:32:41 Epoch: 1, Batch: 1400, Loss: 2.801110825538635
2022-07-07 at 12:33:18 Epoch: 1, Batch: 1500, Loss: 2.7475031852722167
2022-07-07 at 12:35:03 Epoch: 1, Testing Loss: 2.7056237058990225
2022-07-07 at 12:35:40 Epoch: 1, Batch: 1600, Loss: 2.7650684618949892
2022-07-07 at 12:36:16 Epoch: 1, Batch: 1700, Loss: 2.7749415183067323
2022-07-07 at 12:36:53 Epoch: 1, Batch: 1800, Loss: 2.714240860939026
2022-07-07 at 12:37:30 Epoch: 1, Batch: 1900, Loss: 2.787028751373291
